<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Logistic Regression | Sarah Nagy</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<h1>Logistic Regression for Kaggle's Titanic Survivor Prediction Competition</h1>
						
					</header>
				<!-- Main -->
					<div id="main">

						<!-- Content -->
							<section id="content" class="main">
								<!-- <span class="image main"><img src="images/pic04.jpg" alt="" /></span> -->
								<h2>Background and Goals</h2>
								<p>To practice data cleaning and logistic regression for predictive modeling, I participated in Kaggle's popular Titanic Survivor Prediction competition. The premise is to predict whether passengers survived based on a data set containing passenger's names, ages, genders, number of family members aboard the ship, ticket class, ticket I.D., fare paid, and location of embarkment. Kaggle provides a large training set including survival information and a smaller test set to submit back to Kaggle with your predictions. This project required me to clean the data by finding appropriate replacements for missing data, and transforming categorical variables into binary operators. I also practiced randomizing the training set to get a smaller trainging and set set from my given data, applying logistic regression, and analyzing the results. I used Python for the data cleaning and R for the data analysis.</p>
								<h2>Getting Started</h2>
								<p>First I did some exploratory analysis on this data and found that there were missing values in the age and embarkment location categories. I also found that sex and embarkment location were non-numerical categorical variables, while the rest were quantitative. I wrote the following Python code to read the given training data Excel sheet and return a new Excel file with new categories, "is_female", "is_male", "emb_is_Q" for an embarkment location of Queenstown, "emb_is_S" for Southampton, and "emb_is_C" for Cherbourg. These new variables allow for the use of binary operators, which will be very useful for the logistic regression later on.   </p>								
								<p>The following is the Python code I wrote for this step:</p>
								<pre><code>surv = open('test.csv','r')
new = open('test_ready.csv', 'w')

def get_ready(surv, new):
    new.writelines(['Pclass,','is_female,','is_male,','age,','SibSp,','Parch,','Fare,','emb_is_Q,','emb_is_S,','emb_is_C,','Survived\n'])
    surv.readline()
    for line in surv.readlines():
        new_values = []
        values = line.split(",")
        new_values.append(str(values[2])+",")
        if values[5] == 'female':
            new_values.append("1,")
            new_values.append("0,")
        elif values[5] == 'male':
            new_values.append("0,")
            new_values.append("1,")
        else:
            new_values.append(",")
        new_values.append(str(values[6])+",")
        new_values.append(str(values[7])+",")
        new_values.append(str(values[8])+",")
        new_values.append(str(values[10])+",")
        if values[12] == 'Q\n':
            new_values.append("1,")
            new_values.append("0,")
            new_values.append("0,")
        elif values[12] == 'S\n':
            new_values.append("0,")
            new_values.append("1,")
            new_values.append("0,")
        elif values[12] == 'C\n':
            new_values.append("0,")
            new_values.append("0,")
            new_values.append("1,")
        else:
            new_values.append(",")
            new_values.append(",")
            new_values.append(",")
        new_values.append(str(values[1])+"\n")
        new.writelines(new_values)
get_ready(surv, new)

surv.close()
new.close()
</pre></code>
								<p>Now that I had all of the data in a useable form, I looked at missing data and associated statistucs. I moved over to RStudio to take advantage of some of its great built in functions. Using the summary function, I found that both age and embarkment location had missing data. I decided to replace the missing age data with the median age- 28 years old. I chose the median because it is more resistant to outliers than mean. I decided to replace missing embarkment location values with the most commonly occuring embarkment location- Southampton. I used the following code to take care of the missing data problem.</p>
								<pre><code>train$age[is.na(train$age)]<- 28
train$emb_is_Q[is.na(train$emb_is_Q)] <- 0
train$emb_is_C[is.na(train$emb_is_C)] <- 0
train$emb_is_S[is.na(train$emb_is_S)] <- 1</pre></code>
								<p>I ran R's summary function again for another check and found there was no missing data and that each variable was in a quantitative form. Next I moved over to GNU Octave for the proper anlysis. I spit up my given "training data" into its own training and test set so that I could test my own model before submitting it to Kaggle. I then applied mean normalization and feature scaling in order to give each of the features equal weighting to improve my model.  </p>
								<pre><code>
</pre></code>
									<p>The MSREs calculated for each set was pretty similar, around ADD VALUE!!!!!!!!!!, so this is a good indication of how well this model will preform on new data.</p>
									<h2>Conclusion and Next Steps</h2>
									<p>The MSRE and NMSRE provide a way to compare different models to see which is a better fit, because they are a way of measuring the difference between the predicted and actual observed values. NMSRE values range from 0 to 1, where a 0 would mean that there was no difference between the predictions and observed values. The NMSRE value that I found is not particularly close to 0. In order to lower this value, a next possible step could be to try ignoring some of the features to see if some of them are actually hindering our fit. If this doesn't work, we could try to gather more data in order ot have a larger training set. Whether or not we would take these steps depends on how accurate this model needs to be. A NMRSE of INSERT VALUE HERE!!!!!!!!! may be satisfactory in some situations.</p>
							</section>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<section>
							<h2>Aliquam sed mauris</h2>
							<p>Sed lorem ipsum dolor sit amet et nullam consequat feugiat consequat magna adipiscing tempus etiam dolore veroeros. eget dapibus mauris. Cras aliquet, nisl ut viverra sollicitudin, ligula erat egestas velit, vitae tincidunt odio.</p>
							<ul class="actions">
								<li><a href="#" class="button">Learn More</a></li>
							</ul>
						</section>
						<section>
							<h2>Etiam feugiat</h2>
							<dl class="alt">
								<dt>Location</dt>
								<dd>Bozeman, MT 59715 &bull; USA</dd>
								<dt>Email</dt>
								<dd><a href="#">snsarahmarienagy@gmail.com</a></dd>
							</dl>
							<ul class="icons">
								<li><a href="https://github.com/SarahMari" class="icon brands fa-github alt"><span class="label">GitHub</span></a></li>
								<li><a href="#" class="icon brands fa-dribbble alt"><span class="label">Dribbble</span></a></li>
							</ul>
						</section>
						<p class="copyright">&copy; Untitled. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
