<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Principle Component Analysis</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<h1>Principle Component Analysis</h1>
						<p>Dimensionality Reduction</p>
					</header>

				<!-- Main -->
					<div id="main">

						<!-- Content -->
							<section id="content" class="main">
								
								<h2>Addressing the problem of dimensionality reduction</h2>
								<p>PCA is a tool which finds similarities between variables in a dataset and can replace many variables with a few new, unnamed variables which represent the data instead. This can be useful for simplifying the model and speeding up processing. It can also be useful for identifying trends in the data and data visualization.</p>
								<p>This tool is only useful if it is used in such a way that too much meaning from the data isn't lost. You can imagine if the data were to be compressed down too much, one could come up with a very simple model, but it would no longer provide meaningful information about the original dataset. Or, if it did, it might provide some insights, but lose out on others. In order to find the sweet spot for reducing dimensions while retaining the data's essence, we can use retention of variability as a quantitative metric. As long as we retain 95-99% of the variability in our data, we can feel confident that the dimensionality reduction hasn't lost too much information. </p>
								<h2>Using PCA on heart attack data</h2>
								<p>I practiced using this tool on a data set about heart attacks uploaded to Kaggle by user @nareshbhat. This data set contains 14 features such as age, gender, cholesteral levels, and chest pain type as well as a binary predictor for heart attack risk. I applied PCA in GNU Octave to see how much I could reduce the dimensionality while retaining 95% and then 99% of the variability of the data.</p>
								<p>First I preprocessed the data by applying feature scaling and mean normalization. Mean normalization but always be done before applying PCA, and feature scaling is usually a good idea. The I used the built-in sigular value decomposition function to find my U, S, and V matrices, and then I calculated the variability retained if I chose to reduce to one feature. The resultant variability retained was about 28%. I increased the number of fetures I reduced to until I got a variability retained value of 95% and then up to 99%. </p>
								<pre><code>%Read and load the data
data = csvread(file_name);
[a ,b] = size(data);
%split into X and Y
X = data(:,1:(b-1));
y = data(:,b);
%initialize helpful values
[m, n] = size(X);

%feature scaling

for i = 1:n
  X(:,i) = X(:,i)./(max(X(:,i)));
  endfor

%mean normalization

for i = 1:n
  X(:,i) = X(:,i)-mean(X(:,i));
endfor


%compute covariance matrix called sigma

Sigma = (1/m)*(X'*X);

%compute eigenvectors of the matrix using built-in singular value decomposition function
[U, S, V] = svd(Sigma);

%define new matrix U_red which is the first k columns of U
U_red = U(:,1:k);

%testing variance retention
%start at k = 1 and increase until ret reaches .99
ret = sum(sum(S(:,1:k)))/sum(sum(S))

%compute new compressed data matrix Z

Z =  X * U_red;

</pre></code>
								<body><img src="PCA.png" alt="Test Image" width = 890/></body>
								<p>These results show that we can reduce down from the original 13 input features to 9 input features while retaining 95% of the variability. We can reduce down to 11 while retaining a whole 99%.</p>
							</section>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<section>
							<h2>About Me</h2>
							<p>I am a data scientist from Montana with a background in physics and statistics. I am very interested in machine learning and big data analysis. Thanks for taking the time to look at my work. Please reach out if you have any questions for me. </p>
							<ul class="actions">
							</ul>
						</section>
						<section>
							<h2>Information</h2>
							<dl class="alt">
								<dt>Address</dt>
								<dd>Bozeman, MT &bull; USA</dd>
								<dt>Email</dt>
								<dd><a href="#">s.nagy.4343@gmail.com</a></dd>
							</dl>
							<ul class="icons">
								<li><a href="https://github.com/SarahMari" class="icon brands fa-github alt"><span class="label">GitHub</span></a></li>
								<li><a href= "http://linkedin.com/in/sarah-nagy-51412152" class = "icon brands fa-linkedin alt"><span class ="label"><Linkedin</span></a></li>
							</ul>
						</section>
						
					</footer>


			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
